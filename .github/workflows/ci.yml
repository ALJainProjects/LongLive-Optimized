name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test-cpu:
    name: CPU Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest torch --index-url https://download.pytorch.org/whl/cpu
          pip install numpy

      - name: Run CPU integration tests
        run: |
          pytest tests/test_integration.py -v --tb=short

      - name: Run config validation tests
        run: |
          python -c "
          from optimizations.config import OptimizationConfig
          for preset in ['quality', 'balanced', 'speed', 'turbo', 'turbo_fp8', 'ultra', 'low_memory']:
              config = getattr(OptimizationConfig, f'preset_{preset}')()
              assert len(config.denoising_steps) > 0
              print(f'{preset}: {len(config.denoising_steps)} steps')
          print('All presets validated!')
          "

  test-gpu:
    name: GPU Tests
    runs-on: ubuntu-latest
    # Only run on main branch or if explicitly requested
    if: github.ref == 'refs/heads/main' || contains(github.event.pull_request.labels.*.name, 'run-gpu-tests')

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest torch numpy

      - name: Check CUDA availability
        run: |
          python -c "
          import torch
          print(f'CUDA available: {torch.cuda.is_available()}')
          if torch.cuda.is_available():
              print(f'GPU: {torch.cuda.get_device_name(0)}')
          "

      - name: Run GPU tests (skip if no GPU)
        run: |
          pytest tests/test_gpu_integration.py -v --tb=short || echo "GPU tests skipped (no GPU available)"

  lint:
    name: Lint
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install linters
        run: |
          pip install ruff

      - name: Run ruff
        run: |
          ruff check optimizations/ benchmarks/ tests/ --ignore E501,F401 || true

  type-check:
    name: Type Check
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install mypy torch numpy

      - name: Run mypy
        run: |
          mypy optimizations/config.py --ignore-missing-imports || true

  benchmark-smoke:
    name: Benchmark Smoke Test
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install torch --index-url https://download.pytorch.org/whl/cpu
          pip install numpy

      - name: Verify benchmark imports
        run: |
          python -c "
          from benchmarks.kernel_profiler import KernelProfiler, KernelTimings
          from benchmarks.benchmark_suite import BenchmarkConfig
          print('Benchmark imports successful!')
          "

      - name: Verify kernel profiler
        run: |
          python -c "
          from benchmarks.kernel_profiler import KernelProfiler
          profiler = KernelProfiler(enabled=False)
          with profiler.profile('test'):
              pass
          print('Kernel profiler works!')
          "
